{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is :\n",
    "1. A replacement for NumPy to use the power of GPUs\n",
    "2. a deep learning research platform that provides maximum flexibility and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function # 即使在python2.X，使用print就得像python3.X那样加括号使用。python2.X中print不需要括号，而在python3.X中则需要。\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7311e-29,  3.0782e-41,  3.9506e-29],\n",
      "        [ 4.5800e-41,  9.5415e-26,  4.5800e-41],\n",
      "        [-2.6571e-30,  3.0782e-41, -2.6571e-30],\n",
      "        [ 3.0782e-41,  6.8893e-25,  4.5800e-41],\n",
      "        [ 6.7912e-25,  4.5800e-41,  3.0673e-25]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Tensors:\n",
    "x = torch.empty(5, 3)\n",
    "x = torch.rand(5,3)\n",
    "x = torch.zeros(5,3,dtype=torch.long)\n",
    "x = torch.tensor([5.5,3])\n",
    "x = x.new_ones(5,3,dtype=torch.double)\n",
    "x = torch.randn_like(x, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3782, 1.5252, 1.2237],\n",
      "        [0.8913, 0.7690, 0.8811],\n",
      "        [0.4292, 0.9464, 0.4922],\n",
      "        [1.1818, 1.2640, 0.3599],\n",
      "        [0.5096, 0.8927, 0.7714]])\n",
      "tensor([[1.3782, 1.5252, 1.2237],\n",
      "        [0.8913, 0.7690, 0.8811],\n",
      "        [0.4292, 0.9464, 0.4922],\n",
      "        [1.1818, 1.2640, 0.3599],\n",
      "        [0.5096, 0.8927, 0.7714]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.3782, 1.5252, 1.2237],\n",
       "        [0.8913, 0.7690, 0.8811],\n",
       "        [0.4292, 0.9464, 0.4922],\n",
       "        [1.1818, 1.2640, 0.3599],\n",
       "        [0.5096, 0.8927, 0.7714]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Operators\n",
    "# 2.1 ADD\n",
    "x = torch.rand(5,3)\n",
    "y = torch.rand(5, 3)\n",
    "\n",
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.9678, -0.7444, -2.0878, -0.5367])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([-0.5224])\n",
      "-0.522361934185\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Indexing\n",
    "x = torch.randn(4, 4)\n",
    "\n",
    "print(x[:, 1])\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())\n",
    "\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 3. Numpy Bridge\n",
    "# From tensor to numpy\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# From numpy to tensor\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Cuda \n",
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
